# RL^2 방향 목표 보상 환경 설정

# 일반 환경 설정
# ----------
# 메타-트레이닝에 대한 태스크들의 수
train_tasks: 2

# 메타-태스팅에 대한 태스크들이 수
test_tasks: 2

# 은닉 유닛의 차원의 수
hidden_dim: 64

# RL^2 환경 설정
# ------------
rl2_params:
    # 트레이닝에 대한 반복 수
    num_iterations: 1000
    # 트레이닝에서 수집할 샘플 수
    num_samples: 800
    # 환경에 대한 최대 스텝 수
    max_step: 200
    # 트레이닝에 대한 태스크 샘플 수
    meta_batch_size: 4
    # 조기 중단 조건의 수
    num_stop_conditions: 3
    # 조기 중단 조건에서 사용되는 목표 값
    stop_goal: 180

# PPO 환경 설정
# -----------
ppo_params:
    # 할인률
    gamma: 0.99
    # 반복 당 취할 에폭 수
    num_epochs: 10
    # 각 에폭에서 취할 미니배치의 수
    mini_batch_size: 32
    # Clipping에 쓰일 파라미터
    clip_param: 0.3
    # 학습률
    learning_rate: 0.0001
