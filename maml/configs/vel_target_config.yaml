# Velocity target reward configs

# General setup
# -------------
# Number of tasks for meta-train
train_tasks: 15

# Number of tasks for meta-test
test_tasks: 15

# Number of hidden units in neural networks
hidden_dims: [300, 300, 300]

maml_params:
    # Number of training iterations
    train_iters: 200
    # Number of task samples for training
    num_sample_tasks: 5
    # Number of samples to train
    train_samples: 200
    # Maximum step for the environment
    max_step: 200
    # Number of samples to test
    test_samples: 200
    # Number of inner adaptation steps for the MAML algorithm
    inner_adaptation_steps: 1
    # Learning rate of inner adaptation
    inner_learning_rate: 0.1
    # Number of PPO steps per meta-update iteration
    maml_optimizer_steps: 5
    # Learning rate of PPO losses
    learning_rate: 0.001

# PPO setup
# ---------
ppo_params:
    # PPO clip parameter
    clip_param: 0.3
    # coefficient of the value function 
    vf_loss_coeff: 0.5
    # Learning rate of value function
    vf_learning_rate: 0.001